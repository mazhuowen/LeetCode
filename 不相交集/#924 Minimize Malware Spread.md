[toc]

In a network of nodes, each node $i$ is directly connected to another node $j$ if and only if `graph[i][j] = 1`.

Some nodes `initial` are initially infected by malware.  Whenever two nodes are directly connected and at least one of those two nodes is infected by malware, both nodes will be infected by malware.  This spread of malware will continue until no more nodes can be infected in this manner.

Suppose `M(initial)` is the final number of nodes infected with malware in the entire network, after the spread of malware stops.

We will remove one node from the initial list.  Return the node that if removed, would minimize `M(initial)`.  If multiple nodes could be removed to minimize `M(initial)`, return such a node with the smallest index.

Note that if a node was removed from the `initial` list of infected nodes, it may still be infected later as a result of the malware spread.



**Note**:

* $1 < \text{graph.length} = \text{graph[0].length} \le 300$
* $0 \le \text{graph[i][j]} == \text{graph[j][i]} \le 1$
* $\text{graph[i][i]} = 1$
* $1 \le \text{initial.length} < \text{graph.length}$
* $0 \le \text{initial[i]} < \text{graph.length}$



## 题目解读

&emsp;给定网络初始连接情况和受恶意软件感染的网络节点列表，找到一个结点删除使得最终收到恶意软件影响的结点数目最小，如果有多个结点，则返回索引最小的结点。

```java
class Solution {
    public int minMalwareSpread(int[][] graph, int[] initial) {

    }
}
```

## 程序设计

* 仔细分析得，对于只包含一个恶意结点的局部网络，只要删除这个恶意网络，剩下的结点就会安全，如果存在多个局部网络都包含一个恶意结点，则选择规模最大的局部网络，这样删除恶意结点后得到的安全的结点最多。
* 如果不存在只包含一个恶意结点的网络，则删除索引最小的恶意点即可。
* 实际就是连通子图的统计和判断，首先根据图得到连通分量，然后连通分量包含恶意结点的数目，最后得到结果。

```java
class Solution {
    public int minMalwareSpread(int[][] graph, int[] initial) {
        // 将连通分量记录
        DisJoint disJoint = new DisJoint(graph.length);
        for (int i = 0; i < graph.length; i++) {
            for (int j = i + 1; j < graph.length; j++) {
                if (graph[i][j] == 1) disJoint.union(disJoint.find(i), disJoint.find(j));
            }
        }
        // 记录initial中的最小的结点
        int minNode = graph.length;
        // 记录每个不相交集恶意节点的数目
        Map<Integer, Integer> counter = new HashMap<>();
        // 记录根与恶意结点映射
        Map<Integer, Integer> record = new HashMap<>();
        for(int i = 0; i < initial.length; i++) {
            minNode = Math.min(minNode, initial[i]);
            int root = disJoint.find(initial[i]);
            counter.put(root, counter.getOrDefault(root, 0) + 1);
            record.put(root, initial[i]);
        }
        // 遍历计数，找到只包含一个恶意结点且尺寸最大的集合
        int singleNode = -1;
        for(Map.Entry<Integer, Integer> count : counter.entrySet()) {
            if(count.getValue() == 1) {
                if(singleNode == -1) singleNode = count.getKey();
                // 都是一个恶意软件，找到尺寸最大的
                else {
                    singleNode = disJoint.getSetSize(singleNode) >= disJoint.getSetSize(count.getKey()) ? singleNode : count.getKey();
                }
            }
        }
        // 不存在只包含一个恶意结点的情况，返回最小结点
        if(singleNode == -1) return minNode;
        // 找到对应的恶意结点，返回即可
        return record.get(singleNode);
    }
}

class DisJoint {
    private int size;
    private int[] tree;

    DisJoint(int size) {
        this.size = size;
        this.tree = new int[size];
        Arrays.fill(tree, -1);
    }

    public void union(int root1, int root2) {
        if(tree[root1] >= 0 || tree[root2] >= 0) throw new IllegalArgumentException("not a root");
        if(root1 == root2) return;

        if(tree[root1] <= tree[root2]) {
            tree[root1] += tree[root2];
            tree[root2] = root1;
        } else {
            tree[root2] += tree[root1];
            tree[root1] = root2;
        }
        size--;
    }

    public int find(int idx) {
        if(tree[idx] < 0) return idx;
        return tree[idx] = find(tree[idx]);
    }

    public int size() {
        return size;
    }

    public int getSetSize(int idx) {
        return -tree[find(idx)];
    }
}
```

## 性能分析

&emsp;时间复杂度为$O(N^2 + K)$，空间复杂度为$O(N)$，其中$K$为恶意结点数目。

执行用时：7ms，在所有java提交中击败了95.80%的用户。

内存消耗：55.5MB，在所有java提交中击败了100.00%的用户。

## 官方解题

&emsp;除了不相交集的思路，官方还提供了深度搜索的思路，使用深度搜索来遍历连通分量，其余思路都一致。